{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LeakyReLU,PReLU,ELU\n",
    "from keras.layers import Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\v-narku\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\v-narku\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\base.py:464: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "C:\\Users\\v-narku\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "df=pd.read_csv(r'C:\\Users\\v-narku\\Desktop\\pythonPractices\\Real_data.csv')\n",
    "X=df.iloc[:,:-1]\n",
    "Y=df['PM2.5']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=0)\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.75895818,  0.73783784,  0.7853625 , ...,  1.41239559,\n",
       "        -0.80938064, -0.71277708],\n",
       "       [-0.28099067, -0.0775162 , -0.36192249, ..., -0.56226796,\n",
       "        -1.26269882, -1.40683483],\n",
       "       [ 0.68869137,  0.44134547,  0.49854125, ...,  1.41239559,\n",
       "         0.12111455,  0.33419139],\n",
       "       ...,\n",
       "       [-1.40525971, -1.53032885, -1.37262593, ..., -1.54959974,\n",
       "        -1.26269882, -0.92452351],\n",
       "       [ 0.74490482,  0.67853937,  1.00389297, ...,  0.26050852,\n",
       "        -0.11747396, -0.07753779],\n",
       "       [-0.21072386, -0.10716543, -0.52582034, ..., -1.05593385,\n",
       "        -0.49921558, -0.07753779]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_66 (Dense)             (None, 128)               1152      \n",
      "_________________________________________________________________\n",
      "dense_67 (Dense)             (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dense_68 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_69 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_70 (Dense)             (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 166,017\n",
      "Trainable params: 166,017\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\v-narku\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:21: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 245 samples, validate on 122 samples\n",
      "Epoch 1/100\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 100.2442 - mean_absolute_error: 100.2442 - val_loss: 81.3770 - val_mean_absolute_error: 81.3770\n",
      "Epoch 2/100\n",
      "245/245 [==============================] - 0s 359us/step - loss: 64.1170 - mean_absolute_error: 64.1170 - val_loss: 55.5187 - val_mean_absolute_error: 55.5187\n",
      "Epoch 3/100\n",
      "245/245 [==============================] - 0s 343us/step - loss: 52.9467 - mean_absolute_error: 52.9467 - val_loss: 52.3168 - val_mean_absolute_error: 52.3168\n",
      "Epoch 4/100\n",
      "245/245 [==============================] - 0s 392us/step - loss: 52.2848 - mean_absolute_error: 52.2848 - val_loss: 51.3070 - val_mean_absolute_error: 51.3070\n",
      "Epoch 5/100\n",
      "245/245 [==============================] - 0s 343us/step - loss: 49.9792 - mean_absolute_error: 49.9792 - val_loss: 51.0454 - val_mean_absolute_error: 51.0454\n",
      "Epoch 6/100\n",
      "245/245 [==============================] - 0s 343us/step - loss: 49.1359 - mean_absolute_error: 49.1359 - val_loss: 49.4023 - val_mean_absolute_error: 49.4023\n",
      "Epoch 7/100\n",
      "245/245 [==============================] - 0s 416us/step - loss: 48.5273 - mean_absolute_error: 48.5273 - val_loss: 49.0875 - val_mean_absolute_error: 49.0875\n",
      "Epoch 8/100\n",
      "245/245 [==============================] - 0s 477us/step - loss: 49.5317 - mean_absolute_error: 49.5317 - val_loss: 52.8059 - val_mean_absolute_error: 52.8059\n",
      "Epoch 9/100\n",
      "245/245 [==============================] - 0s 469us/step - loss: 48.1255 - mean_absolute_error: 48.1255 - val_loss: 48.1557 - val_mean_absolute_error: 48.1557\n",
      "Epoch 10/100\n",
      "245/245 [==============================] - 0s 559us/step - loss: 47.0120 - mean_absolute_error: 47.0120 - val_loss: 47.8551 - val_mean_absolute_error: 47.8551\n",
      "Epoch 11/100\n",
      "245/245 [==============================] - 0s 432us/step - loss: 47.3792 - mean_absolute_error: 47.3792 - val_loss: 50.0881 - val_mean_absolute_error: 50.0881\n",
      "Epoch 12/100\n",
      "245/245 [==============================] - 0s 388us/step - loss: 46.8809 - mean_absolute_error: 46.8809 - val_loss: 49.6999 - val_mean_absolute_error: 49.6999\n",
      "Epoch 13/100\n",
      "245/245 [==============================] - 0s 416us/step - loss: 47.9552 - mean_absolute_error: 47.9552 - val_loss: 48.4206 - val_mean_absolute_error: 48.4206\n",
      "Epoch 14/100\n",
      "245/245 [==============================] - 0s 420us/step - loss: 46.3270 - mean_absolute_error: 46.3270 - val_loss: 47.5327 - val_mean_absolute_error: 47.5327\n",
      "Epoch 15/100\n",
      "245/245 [==============================] - 0s 432us/step - loss: 45.9815 - mean_absolute_error: 45.9815 - val_loss: 48.1760 - val_mean_absolute_error: 48.1760\n",
      "Epoch 16/100\n",
      "245/245 [==============================] - 0s 367us/step - loss: 45.9903 - mean_absolute_error: 45.9903 - val_loss: 47.5279 - val_mean_absolute_error: 47.5279\n",
      "Epoch 17/100\n",
      "245/245 [==============================] - 0s 359us/step - loss: 45.5476 - mean_absolute_error: 45.5476 - val_loss: 48.3383 - val_mean_absolute_error: 48.3383\n",
      "Epoch 18/100\n",
      "245/245 [==============================] - 0s 388us/step - loss: 44.9376 - mean_absolute_error: 44.9376 - val_loss: 47.6777 - val_mean_absolute_error: 47.6777\n",
      "Epoch 19/100\n",
      "245/245 [==============================] - 0s 326us/step - loss: 45.6514 - mean_absolute_error: 45.6514 - val_loss: 47.7383 - val_mean_absolute_error: 47.7383\n",
      "Epoch 20/100\n",
      "245/245 [==============================] - 0s 449us/step - loss: 45.3431 - mean_absolute_error: 45.3431 - val_loss: 47.5014 - val_mean_absolute_error: 47.5014\n",
      "Epoch 21/100\n",
      "245/245 [==============================] - 0s 371us/step - loss: 45.4749 - mean_absolute_error: 45.4749 - val_loss: 47.6964 - val_mean_absolute_error: 47.6964\n",
      "Epoch 22/100\n",
      "245/245 [==============================] - 0s 363us/step - loss: 45.0415 - mean_absolute_error: 45.0415 - val_loss: 48.8766 - val_mean_absolute_error: 48.8766\n",
      "Epoch 23/100\n",
      "245/245 [==============================] - 0s 392us/step - loss: 46.1216 - mean_absolute_error: 46.1216 - val_loss: 47.5469 - val_mean_absolute_error: 47.5469\n",
      "Epoch 24/100\n",
      "245/245 [==============================] - 0s 465us/step - loss: 44.9137 - mean_absolute_error: 44.9137 - val_loss: 47.2746 - val_mean_absolute_error: 47.2746\n",
      "Epoch 25/100\n",
      "245/245 [==============================] - 0s 563us/step - loss: 45.0171 - mean_absolute_error: 45.0171 - val_loss: 47.2962 - val_mean_absolute_error: 47.2962\n",
      "Epoch 26/100\n",
      "245/245 [==============================] - 0s 416us/step - loss: 45.1464 - mean_absolute_error: 45.1464 - val_loss: 48.0308 - val_mean_absolute_error: 48.0308\n",
      "Epoch 27/100\n",
      "245/245 [==============================] - 0s 371us/step - loss: 44.7043 - mean_absolute_error: 44.7043 - val_loss: 49.0894 - val_mean_absolute_error: 49.0894\n",
      "Epoch 28/100\n",
      "245/245 [==============================] - 0s 436us/step - loss: 45.3650 - mean_absolute_error: 45.3650 - val_loss: 47.7342 - val_mean_absolute_error: 47.7342\n",
      "Epoch 29/100\n",
      "245/245 [==============================] - 0s 347us/step - loss: 44.4609 - mean_absolute_error: 44.4609 - val_loss: 47.7659 - val_mean_absolute_error: 47.7659\n",
      "Epoch 30/100\n",
      "245/245 [==============================] - 0s 351us/step - loss: 45.2389 - mean_absolute_error: 45.2389 - val_loss: 48.1445 - val_mean_absolute_error: 48.1445\n",
      "Epoch 31/100\n",
      "245/245 [==============================] - 0s 351us/step - loss: 45.1481 - mean_absolute_error: 45.1481 - val_loss: 47.7018 - val_mean_absolute_error: 47.7018\n",
      "Epoch 32/100\n",
      "245/245 [==============================] - 0s 371us/step - loss: 44.5964 - mean_absolute_error: 44.5964 - val_loss: 49.3801 - val_mean_absolute_error: 49.3801\n",
      "Epoch 33/100\n",
      "245/245 [==============================] - 0s 310us/step - loss: 45.6052 - mean_absolute_error: 45.6052 - val_loss: 47.0719 - val_mean_absolute_error: 47.0719\n",
      "Epoch 34/100\n",
      "245/245 [==============================] - 0s 306us/step - loss: 44.3438 - mean_absolute_error: 44.3438 - val_loss: 49.1520 - val_mean_absolute_error: 49.1520\n",
      "Epoch 35/100\n",
      "245/245 [==============================] - 0s 335us/step - loss: 44.7726 - mean_absolute_error: 44.7726 - val_loss: 49.1160 - val_mean_absolute_error: 49.1160\n",
      "Epoch 36/100\n",
      "245/245 [==============================] - 0s 392us/step - loss: 45.7221 - mean_absolute_error: 45.7221 - val_loss: 47.8284 - val_mean_absolute_error: 47.8284\n",
      "Epoch 37/100\n",
      "245/245 [==============================] - 0s 322us/step - loss: 43.7818 - mean_absolute_error: 43.7818 - val_loss: 47.2586 - val_mean_absolute_error: 47.2586\n",
      "Epoch 38/100\n",
      "245/245 [==============================] - 0s 306us/step - loss: 44.0966 - mean_absolute_error: 44.0966 - val_loss: 47.6148 - val_mean_absolute_error: 47.6148\n",
      "Epoch 39/100\n",
      "245/245 [==============================] - 0s 371us/step - loss: 43.8028 - mean_absolute_error: 43.8028 - val_loss: 47.9574 - val_mean_absolute_error: 47.9574\n",
      "Epoch 40/100\n",
      "245/245 [==============================] - 0s 351us/step - loss: 43.6874 - mean_absolute_error: 43.6874 - val_loss: 48.1027 - val_mean_absolute_error: 48.1027\n",
      "Epoch 41/100\n",
      "245/245 [==============================] - 0s 400us/step - loss: 44.2832 - mean_absolute_error: 44.2832 - val_loss: 48.2462 - val_mean_absolute_error: 48.2462\n",
      "Epoch 42/100\n",
      "245/245 [==============================] - 0s 383us/step - loss: 43.8200 - mean_absolute_error: 43.8200 - val_loss: 47.4199 - val_mean_absolute_error: 47.4199\n",
      "Epoch 43/100\n",
      "245/245 [==============================] - 0s 396us/step - loss: 43.3417 - mean_absolute_error: 43.3417 - val_loss: 47.5729 - val_mean_absolute_error: 47.5729\n",
      "Epoch 44/100\n",
      "245/245 [==============================] - 0s 343us/step - loss: 43.1327 - mean_absolute_error: 43.1327 - val_loss: 47.8006 - val_mean_absolute_error: 47.8006\n",
      "Epoch 45/100\n",
      "245/245 [==============================] - 0s 335us/step - loss: 43.4564 - mean_absolute_error: 43.4564 - val_loss: 48.5625 - val_mean_absolute_error: 48.5625\n",
      "Epoch 46/100\n",
      "245/245 [==============================] - 0s 306us/step - loss: 43.0959 - mean_absolute_error: 43.0959 - val_loss: 48.5055 - val_mean_absolute_error: 48.5055\n",
      "Epoch 47/100\n",
      "245/245 [==============================] - 0s 432us/step - loss: 43.9780 - mean_absolute_error: 43.9780 - val_loss: 48.2626 - val_mean_absolute_error: 48.2626\n",
      "Epoch 48/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "245/245 [==============================] - 0s 302us/step - loss: 43.4432 - mean_absolute_error: 43.4432 - val_loss: 49.0088 - val_mean_absolute_error: 49.0088\n",
      "Epoch 49/100\n",
      "245/245 [==============================] - 0s 339us/step - loss: 44.2725 - mean_absolute_error: 44.2725 - val_loss: 48.6723 - val_mean_absolute_error: 48.6723\n",
      "Epoch 50/100\n",
      "245/245 [==============================] - 0s 310us/step - loss: 42.8193 - mean_absolute_error: 42.8193 - val_loss: 48.0296 - val_mean_absolute_error: 48.0296\n",
      "Epoch 51/100\n",
      "245/245 [==============================] - 0s 306us/step - loss: 43.2133 - mean_absolute_error: 43.2133 - val_loss: 48.4054 - val_mean_absolute_error: 48.4054\n",
      "Epoch 52/100\n",
      "245/245 [==============================] - 0s 298us/step - loss: 44.4761 - mean_absolute_error: 44.4761 - val_loss: 48.9642 - val_mean_absolute_error: 48.9642\n",
      "Epoch 53/100\n",
      "245/245 [==============================] - 0s 400us/step - loss: 43.6215 - mean_absolute_error: 43.6215 - val_loss: 48.4457 - val_mean_absolute_error: 48.4457\n",
      "Epoch 54/100\n",
      "245/245 [==============================] - 0s 286us/step - loss: 46.0778 - mean_absolute_error: 46.0778 - val_loss: 49.5534 - val_mean_absolute_error: 49.5534\n",
      "Epoch 55/100\n",
      "245/245 [==============================] - 0s 306us/step - loss: 43.4670 - mean_absolute_error: 43.4670 - val_loss: 49.3689 - val_mean_absolute_error: 49.3689\n",
      "Epoch 56/100\n",
      "245/245 [==============================] - 0s 330us/step - loss: 42.4868 - mean_absolute_error: 42.4868 - val_loss: 48.9774 - val_mean_absolute_error: 48.9774\n",
      "Epoch 57/100\n",
      "245/245 [==============================] - 0s 347us/step - loss: 43.2221 - mean_absolute_error: 43.2221 - val_loss: 47.8894 - val_mean_absolute_error: 47.8894\n",
      "Epoch 58/100\n",
      "245/245 [==============================] - 0s 294us/step - loss: 42.6511 - mean_absolute_error: 42.6511 - val_loss: 51.2715 - val_mean_absolute_error: 51.2715\n",
      "Epoch 59/100\n",
      "245/245 [==============================] - 0s 298us/step - loss: 42.5061 - mean_absolute_error: 42.5061 - val_loss: 49.2716 - val_mean_absolute_error: 49.2716\n",
      "Epoch 60/100\n",
      "245/245 [==============================] - 0s 306us/step - loss: 43.5908 - mean_absolute_error: 43.5908 - val_loss: 49.2676 - val_mean_absolute_error: 49.2676\n",
      "Epoch 61/100\n",
      "245/245 [==============================] - 0s 326us/step - loss: 42.0321 - mean_absolute_error: 42.0321 - val_loss: 49.6223 - val_mean_absolute_error: 49.6223\n",
      "Epoch 62/100\n",
      "245/245 [==============================] - 0s 294us/step - loss: 44.4699 - mean_absolute_error: 44.4699 - val_loss: 48.8258 - val_mean_absolute_error: 48.8258\n",
      "Epoch 63/100\n",
      "245/245 [==============================] - 0s 335us/step - loss: 41.8640 - mean_absolute_error: 41.8640 - val_loss: 48.2666 - val_mean_absolute_error: 48.2666\n",
      "Epoch 64/100\n",
      "245/245 [==============================] - 0s 326us/step - loss: 42.0176 - mean_absolute_error: 42.0176 - val_loss: 49.3387 - val_mean_absolute_error: 49.3387\n",
      "Epoch 65/100\n",
      "245/245 [==============================] - 0s 330us/step - loss: 42.4516 - mean_absolute_error: 42.4516 - val_loss: 49.8282 - val_mean_absolute_error: 49.8282\n",
      "Epoch 66/100\n",
      "245/245 [==============================] - 0s 310us/step - loss: 42.5145 - mean_absolute_error: 42.5145 - val_loss: 49.0221 - val_mean_absolute_error: 49.0221\n",
      "Epoch 67/100\n",
      "245/245 [==============================] - 0s 318us/step - loss: 41.8996 - mean_absolute_error: 41.8996 - val_loss: 49.6010 - val_mean_absolute_error: 49.6010\n",
      "Epoch 68/100\n",
      "245/245 [==============================] - 0s 306us/step - loss: 43.8015 - mean_absolute_error: 43.8015 - val_loss: 51.4007 - val_mean_absolute_error: 51.4007\n",
      "Epoch 69/100\n",
      "245/245 [==============================] - 0s 359us/step - loss: 42.3386 - mean_absolute_error: 42.3386 - val_loss: 51.0924 - val_mean_absolute_error: 51.0924\n",
      "Epoch 70/100\n",
      "245/245 [==============================] - 0s 290us/step - loss: 41.7846 - mean_absolute_error: 41.7846 - val_loss: 48.2434 - val_mean_absolute_error: 48.2434\n",
      "Epoch 71/100\n",
      "245/245 [==============================] - 0s 314us/step - loss: 41.5317 - mean_absolute_error: 41.5317 - val_loss: 49.7197 - val_mean_absolute_error: 49.7197\n",
      "Epoch 72/100\n",
      "245/245 [==============================] - 0s 306us/step - loss: 41.1297 - mean_absolute_error: 41.1297 - val_loss: 48.5759 - val_mean_absolute_error: 48.5759\n",
      "Epoch 73/100\n",
      "245/245 [==============================] - 0s 339us/step - loss: 41.1731 - mean_absolute_error: 41.1731 - val_loss: 48.7729 - val_mean_absolute_error: 48.7729\n",
      "Epoch 74/100\n",
      "245/245 [==============================] - 0s 322us/step - loss: 41.3643 - mean_absolute_error: 41.3643 - val_loss: 50.5833 - val_mean_absolute_error: 50.5833\n",
      "Epoch 75/100\n",
      "245/245 [==============================] - 0s 314us/step - loss: 43.1256 - mean_absolute_error: 43.1256 - val_loss: 50.1457 - val_mean_absolute_error: 50.1457\n",
      "Epoch 76/100\n",
      "245/245 [==============================] - 0s 367us/step - loss: 41.3625 - mean_absolute_error: 41.3625 - val_loss: 49.2232 - val_mean_absolute_error: 49.2232\n",
      "Epoch 77/100\n",
      "245/245 [==============================] - 0s 318us/step - loss: 40.9002 - mean_absolute_error: 40.9002 - val_loss: 49.6699 - val_mean_absolute_error: 49.6699\n",
      "Epoch 78/100\n",
      "245/245 [==============================] - 0s 347us/step - loss: 40.9571 - mean_absolute_error: 40.9571 - val_loss: 50.4059 - val_mean_absolute_error: 50.4059\n",
      "Epoch 79/100\n",
      "245/245 [==============================] - 0s 339us/step - loss: 39.9770 - mean_absolute_error: 39.9770 - val_loss: 49.1319 - val_mean_absolute_error: 49.1319\n",
      "Epoch 80/100\n",
      "245/245 [==============================] - 0s 318us/step - loss: 39.1838 - mean_absolute_error: 39.1838 - val_loss: 52.4156 - val_mean_absolute_error: 52.4156\n",
      "Epoch 81/100\n",
      "245/245 [==============================] - 0s 326us/step - loss: 43.2377 - mean_absolute_error: 43.2377 - val_loss: 50.1238 - val_mean_absolute_error: 50.1238\n",
      "Epoch 82/100\n",
      "245/245 [==============================] - 0s 322us/step - loss: 40.1873 - mean_absolute_error: 40.1873 - val_loss: 50.0579 - val_mean_absolute_error: 50.0579\n",
      "Epoch 83/100\n",
      "245/245 [==============================] - 0s 306us/step - loss: 39.9082 - mean_absolute_error: 39.9082 - val_loss: 49.5057 - val_mean_absolute_error: 49.5057\n",
      "Epoch 84/100\n",
      "245/245 [==============================] - 0s 330us/step - loss: 39.5682 - mean_absolute_error: 39.5682 - val_loss: 50.1169 - val_mean_absolute_error: 50.1169\n",
      "Epoch 85/100\n",
      "245/245 [==============================] - 0s 363us/step - loss: 38.9782 - mean_absolute_error: 38.9782 - val_loss: 51.4997 - val_mean_absolute_error: 51.4997\n",
      "Epoch 86/100\n",
      "245/245 [==============================] - 0s 310us/step - loss: 40.2600 - mean_absolute_error: 40.2600 - val_loss: 49.9803 - val_mean_absolute_error: 49.9803\n",
      "Epoch 87/100\n",
      "245/245 [==============================] - 0s 343us/step - loss: 39.3920 - mean_absolute_error: 39.3920 - val_loss: 50.0170 - val_mean_absolute_error: 50.0170\n",
      "Epoch 88/100\n",
      "245/245 [==============================] - 0s 347us/step - loss: 39.2921 - mean_absolute_error: 39.2921 - val_loss: 50.7654 - val_mean_absolute_error: 50.7654\n",
      "Epoch 89/100\n",
      "245/245 [==============================] - 0s 335us/step - loss: 38.5874 - mean_absolute_error: 38.5874 - val_loss: 50.1265 - val_mean_absolute_error: 50.1265\n",
      "Epoch 90/100\n",
      "245/245 [==============================] - 0s 375us/step - loss: 39.1214 - mean_absolute_error: 39.1214 - val_loss: 51.1823 - val_mean_absolute_error: 51.1823\n",
      "Epoch 91/100\n",
      "245/245 [==============================] - 0s 351us/step - loss: 40.1777 - mean_absolute_error: 40.1777 - val_loss: 51.9644 - val_mean_absolute_error: 51.9644\n",
      "Epoch 92/100\n",
      "245/245 [==============================] - 0s 302us/step - loss: 40.4950 - mean_absolute_error: 40.4950 - val_loss: 50.6806 - val_mean_absolute_error: 50.6806\n",
      "Epoch 93/100\n",
      "245/245 [==============================] - 0s 322us/step - loss: 38.3648 - mean_absolute_error: 38.3648 - val_loss: 50.7945 - val_mean_absolute_error: 50.7945\n",
      "Epoch 94/100\n",
      "245/245 [==============================] - ETA: 0s - loss: 37.0138 - mean_absolute_error: 37.013 - 0s 347us/step - loss: 38.1277 - mean_absolute_error: 38.1277 - val_loss: 50.4924 - val_mean_absolute_error: 50.4924\n",
      "Epoch 95/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "245/245 [==============================] - 0s 318us/step - loss: 38.4602 - mean_absolute_error: 38.4602 - val_loss: 51.3247 - val_mean_absolute_error: 51.3247\n",
      "Epoch 96/100\n",
      "245/245 [==============================] - 0s 306us/step - loss: 37.9672 - mean_absolute_error: 37.9672 - val_loss: 50.2497 - val_mean_absolute_error: 50.2497\n",
      "Epoch 97/100\n",
      "245/245 [==============================] - 0s 306us/step - loss: 40.7251 - mean_absolute_error: 40.7251 - val_loss: 50.9184 - val_mean_absolute_error: 50.9184\n",
      "Epoch 98/100\n",
      "245/245 [==============================] - 0s 314us/step - loss: 37.4562 - mean_absolute_error: 37.4562 - val_loss: 49.7528 - val_mean_absolute_error: 49.7528\n",
      "Epoch 99/100\n",
      "245/245 [==============================] - 0s 330us/step - loss: 39.2043 - mean_absolute_error: 39.2043 - val_loss: 50.7462 - val_mean_absolute_error: 50.7462\n",
      "Epoch 100/100\n",
      "245/245 [==============================] - 0s 363us/step - loss: 37.1608 - mean_absolute_error: 37.1608 - val_loss: 50.7487 - val_mean_absolute_error: 50.7487\n"
     ]
    }
   ],
   "source": [
    "NN_model = Sequential()\n",
    "\n",
    "# The Input Layer :\n",
    "NN_model.add(Dense(128, kernel_initializer='normal',input_dim = X_train.shape[1], activation='relu'))\n",
    "\n",
    "# The Hidden Layers :\n",
    "NN_model.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
    "\n",
    "NN_model.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
    "\n",
    "NN_model.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
    "\n",
    "# The Output Layer :\n",
    "NN_model.add(Dense(1, kernel_initializer='normal',activation='linear'))\n",
    "\n",
    "# Compile the network :\n",
    "NN_model.compile(loss='mean_absolute_error', optimizer='Adamax', metrics=['mean_absolute_error'])\n",
    "NN_model.summary()\n",
    "\n",
    "# Fitting the ANN to the Training set\n",
    "model_history=NN_model.fit(X_train, y_train,validation_split=0.33, batch_size = 10, nb_epoch = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 45.81398563205374\n",
      "MSE: 5372.42387168176\n",
      "RMSE: 73.29682033814127\n"
     ]
    }
   ],
   "source": [
    "prediction=NN_model.predict(X_test)\n",
    "print('MAE:', metrics.mean_absolute_error(y_test, prediction))\n",
    "print('MSE:', metrics.mean_squared_error(y_test, prediction))\n",
    "print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, prediction)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
